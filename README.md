# ğŸš€ Centernet_tracking

## Yo, What's This All About? ğŸ˜

Welcome to **Centernet_tracking**, the coolest project for smashing object detection and tracking like a pro!  
Built on the epic **CenterNet** architecture, this bad boy lets you detect and track objects in videos or images with ninja-level precision.

Whether you're diving into computer vision for fun, building the next big thing in surveillance, or creating something wild for autonomous systems â€” this repo is your ticket to greatness!

---

## ğŸ’¥ Why You'll Love It

- ğŸ”¥ **Next-Level Detection**: CenterNet brings the heat with fast and accurate object spotting.  
- ğŸ¯ **Track Like a Boss**: Follow multiple objects across frames like they're your crew.  
- ğŸ¨ **Make It Your Own**: Tweak it, twist it, make it fit your vibe!  
- âš¡ **Ready-to-Roll Models**: Pre-trained models to get you started in a snap.

---

## ğŸ› ï¸ What You Need to Get Started

Make sure youâ€™ve got the following:

- ğŸ Python 3.8+ (because weâ€™re modern like that)  
- ğŸ”¥ PyTorch 1.7.0+ (the engine of our dreams)  
- ğŸ§  OpenCV, NumPy, SciPy (the sidekicks)  
- âš¡ CUDA (optional, for that GPU turbo boost)

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ‰ Letâ€™s Get It Running!

### 1. Grab the Code

```bash
git clone https://github.com/nguyenhuunam852/Centernet_tracking.git
cd Centernet_tracking
```

### 2. Install Requirements

```bash
pip install -r requirements.txt
```

### 3. Download Pretrained Models (optional)

```bash
wget <model_url> -P models/
```

---

## âœ¨ How to Make Magic Happen

### 1. Prep Your Data

Place your images or videos in the `data/` folder.  
Supported formats: COCO, MOT, or custom (check `configs/` for settings).

### 2. Track Like a Superstar

Run detection and tracking on a video or image set:

```bash
python main.py --mode inference --input_path data/your_video.mp4 --output_path output/
```

### 3. Train Your Own Beast

Train the model on your own dataset:

```bash
python main.py --mode train --config configs/default.yaml --data_path data/your_dataset/
```

### 4. Customize Your Ride

Edit `configs/default.yaml` to:

- Pick your model type  
- Set input resolution  
- Choose tracking algorithm (`IOU`, `Kalman`, etc.)  
- Adjust batch size, learning rate, and more

---

## ğŸ”¥ Try This Out!

```bash
# Track objects in a sample video
python main.py --mode inference --input_path data/sample_video.mp4 --output_path output/tracked_video.mp4
```

---

## ğŸ¥ What Youâ€™ll Get

Your tracked videos or annotated images will land in the `output/` folder,  
complete with slick bounding boxes and tracking IDs.

Show off your masterpiece! ğŸ§ ğŸ’»

---

## ğŸ“¦ Pre-trained Models

Pre-trained models coming soon â€” stay tuned!  
Place downloaded weights into the `models/` folder.

---

## ğŸ™Œ Join the Squad!

Wanna make this project even more awesome? Hereâ€™s how to contribute:

1. Fork this repo like itâ€™s hot ğŸ”¥  
2. Create a new branch:  
   ```bash
   git checkout -b my-cool-feature
   ```
3. Commit your changes:  
   ```bash
   git commit -m "Added some epic sauce"
   ```
4. Push it up:  
   ```bash
   git push origin my-cool-feature
   ```
5. Open a Pull Request. Letâ€™s make waves together ğŸŒŠ

---

## ğŸ“„ License

This project is rocking the **MIT License**.  
See the `LICENSE` file for all the legal stuff.

---

## ğŸŒŸ Big Thanks!

- Shoutout to **CenterNet: Objects as Points** for the inspo.  
- Big love to the open-source community for tools & datasets that power this project.

---

## ğŸ’¬ Got Questions? Letâ€™s Chat!

Open an issue on GitHub or DM [nguyenhuunam852](https://github.com/nguyenhuunam852).  
Letâ€™s build something legendary together! ğŸš€
